from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import tensorflow as tf
from imutils.video import VideoStream
import numpy as np
import imutils
import time
import cv2
import os
import base64
import json
import requests

class SocialDistancing:
    def __init__ (self):
        self.websocketServer = 'http://192.168.0.103:3000'
        print("[INFO] loading face detector model...")
        prototxtPath = os.path.sep.join(['face_detector', "deploy.prototxt"])
        weightsPath = os.path.sep.join(['face_detector',"res10_300x300_ssd_iter_140000.caffemodel"])
        self.faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)

        print("[INFO] loading face mask detector model...")
        self.maskNet = load_model('mask_detector2.model')

        print("[INFO] starting video stream...")
        self.vs = VideoStream(src=0).start()

    def detect_and_predict_mask(self, frame, faceNet, maskNet):
        (h, w) = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))
        faceNet.setInput(blob)
        detections = faceNet.forward()

        faces = []
        locs = []
        preds = []
        for i in range(0, detections.shape[2]):
                confidence = detections[0, 0, i, 2]
                if confidence > 0.5:
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (startX, startY, endX, endY) = box.astype("int")

                    (startX, startY) = (max(0, startX), max(0, startY))
                    (endX, endY) = (min(w - 1, endX), min(h - 1, endY))

                    face = frame[startY:endY, startX:endX]
                    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
                    face = cv2.resize(face, (100, 100))
                    face = img_to_array(face)
                    face = preprocess_input(face)

                    faces.append(face)
                    locs.append((startX, startY, endX, endY))
        if len(faces) > 0:
            faces = np.array(faces, dtype="float32")
            preds = maskNet.predict(faces, batch_size=32)
        return (locs, preds)

    def processing_and_sending(self):
time.sleep(2)
        width_frame = 400
        treshold = 100
        faceNet = self.faceNet
        maskNet = self.maskNet
        while True:
		frame = self.vs.read()
            frame = imutils.resize(frame, width=400)
            (locs, preds) = self.detect_and_predict_mask(frame, faceNet, maskNet)
            boxs = []
            x1 = []
            x2 = []
            y1 = []
            y2 = []
            mid_x = []
            for (box, pred) in zip(locs, preds):
                boxs.append(box)
                print(boxs)
                if len(boxs)>1:
                    n = len(boxs)
                    for i in range (0, n):
                        x1.append(boxs[i][0])
                        y1.append(boxs[i][1])
                        x2.append(boxs[i][2])
                        y2.append(boxs[i][3])
                        mid_x.append((boxs[i][0])-(boxs[i][2]))
                    for j in range (0, len(x1)):
                        for i in range (0, len(x1)-j-1):
                            if x2[i]-x1[i]<x2[i+1]-x1[i+1]:
                                x1[i], x2[i], x1[i+1], x2[i+1] = x1[i+1], x2[i+1], x1[i], x2[i]
                    for j in range (1, len(x1)):
                        dis = (x2[j]-x1[j])/2
                        dis = dis - ((x2[j-1]-x1[j-1])/2)
                        dis = dis + ((x1[j-1]*x2[j-1])/(x2[j]-x1[j]))
                        dis = dis / width_frame
                        dis = 1-dis
                        dis = dis * treshold
                        dis = -dis
                    print(dis)
                    if dis < 350 :
                        for j in range (1, len(x1)):
                            cv2.line(frame, (mid_x[j-1], y1[j-1]), (mid_x[j], y1[j]), (255, 0, 0), 1)
                            cv2.putText(frame, 'Too Close', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)
                (startX, startY, endX, endY) = box
                (mask, withoutMask) = pred

                label = "Mask" if mask > withoutMask else "No Mask"
                color = (0, 255, 0) if label == "Mask" else (0, 0, 255)
                label = "{}: {:.2f}%".format(label, max(mask, withoutMask) * 100)
                cv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)
                cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)

	cv2.imshow('frame', frame)
	key = cv2.waitKey(1) & 0xff
	if key == ord('q'):
		break
	cv2.destroyAllWindow()
          #  img_to_base64 = base64.b64encode(cv2.imencode('.jpg', frame)[1]).decode()
           # conv = [{'img' : img_to_base64}]

            #sendData = json.dumps(conv)
            #requests.post(self.websocketServer+"/sd/", json=sendData).json()

if __name__ == '__main__':
    SocialDistancing().processing_and_sending()
